{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585acd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_compression import _compress_model, _retrive_uncompress_matrix\n",
    "import torch\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3b422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████▉             | 225M/335M [00:01<00:00, 185MiB/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/p3iv/lib/python3.7/site-packages/clip/clip.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(url, root)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_764/146500393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ViT-B/16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/p3iv/lib/python3.7/site-packages/clip/clip.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, device, jit, download_root)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MODELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MODELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/.cache/clip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/p3iv/lib/python3.7/site-packages/clip/clip.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(url, root)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_sha256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "load original clip model\n",
    "\"\"\"\n",
    "new_cache_dir = \"/mnt/data/cache\"\n",
    "import os\n",
    "# Set the TRANSFORMERS_CACHE environment variable\n",
    "os.environ['TRANSFORMERS_CACHE'] = new_cache_dir\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/16', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f81613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual - 21\n",
      "key-visual.transformer.resblocks.1.attn.in_proj_weight gonna be compressed\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_764/3139185511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcompress_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclip_compress_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_skipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compress_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLIP_CIFAR100\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_model_performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"layers_skipped{layers_skipped}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hpml_project/E6998/E6998-HPML-TermProject/utils/model_compression.py\u001b[0m in \u001b[0;36m_compress_model\u001b[0;34m(r_model_dict, r_compress_ratio, n_layers, d_visual, d_text)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mr_dim_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mr_compress_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_compress_ratio\u001b[0m\u001b[0;31m#*gp_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mr_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_determine_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_dim_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_dim_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_compress_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;31m#             print(r_rank,r_dim_a,r_dim_b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mr_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'V'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hpml_project/E6998/E6998-HPML-TermProject/utils/model_compression.py\u001b[0m in \u001b[0;36m_determine_rank\u001b[0;34m(r_dim_a, r_dim_b, r_compress_ratio)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mr_compress_ratio\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mr_compress_ratio\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mr_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_compress_ratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr_dim_a\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr_dim_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_dim_a\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mr_dim_b\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "compress_ratio = 0.75\n",
    "clip_compress_state_dict, layers_skipped = _compress_model(state_dict, 70, 200, True, True)\n",
    "from utils.CLIP_CIFAR100 import compute_model_performance\n",
    "print(f\"layers_skipped{layers_skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766d69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_uncompress_state_dict = _retrive_uncompress_matrix(clip_compress_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68046fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 151277313\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for param_tensor in state_dict.values():\n",
    "    total_params += param_tensor.numel()\n",
    "#     print(param_tensor.numel())\n",
    "\n",
    "print(\"Total number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1f9810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 138679080\n"
     ]
    }
   ],
   "source": [
    "total_params_comp = 0\n",
    "for param_tensor in clip_compress_state_dict.values():\n",
    "    if isinstance(param_tensor,dict)==True:\n",
    "        for key,value in param_tensor.items():\n",
    "            total_params_comp += value.numel()\n",
    "    else:\n",
    "        total_params_comp += param_tensor.numel()\n",
    "print(\"Total number of parameters:\", total_params_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94cf85be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08327906379458233"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_params - total_params_comp)/total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ead526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CLIP model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy is 0.012720352564102564\n",
      "Top-5 accuracy is 0.04056490384615385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'top-1': 0.012720352564102564, 'top-5': 0.04056490384615385}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Random Compression for all\" \"2.5% compression\"\n",
    "compute_model_performance(clip_uncompress_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p3iv] *",
   "language": "python",
   "name": "conda-env-p3iv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
