{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d685b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d5c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, BlipModel\n",
    "\n",
    "# model = BlipModel.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "# processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b73694",
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5aaf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b788dd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['model_size'] = \"ViT-B/32\"\n",
    "params['device'] = device if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(params['model_size'], device=params['device'])\n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "print(\"CLIP model loaded\")\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, images):\n",
    "        self.images=images\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.images[index]\n",
    "        return preprocess(X)\n",
    "\n",
    "params = {'batch_size': 32, 'shuffle': False, 'num_workers':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915bb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset=[]\n",
    "correctlabels=[]\n",
    "for image,class_id in cifar100:\n",
    "    testset.append(image)\n",
    "    correctlabels.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6bc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "text_features = model.encode_text(text_inputs).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f24186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = Dataset(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a08f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "testloader = torch.utils.data.DataLoader(test_set, **params)\n",
    "for idx, item in enumerate(tqdm(testloader,desc=\"Inference\")):\n",
    "    with torch.no_grad():\n",
    "        item = item.to(device)\n",
    "        outputs = model.encode_image(item).float()\n",
    "\n",
    "    results.append(outputs)\n",
    "    \n",
    "    \n",
    "img_features = torch.vstack(results[0:-1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddcb1525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9984, 512]), torch.Size([512, 100]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_features.shape, text_features.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c97dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features /= img_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19611613",
   "metadata": {},
   "outputs": [],
   "source": [
    "values,indices = (img_features.squeeze() @ text_features.T).softmax(dim=1).topk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82de10d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy is 0.47766426282051283\n"
     ]
    }
   ],
   "source": [
    "accuracy = {}\n",
    "for idx,item in enumerate(indices):\n",
    "    accuracy[idx] = 0\n",
    "    if (item.item() == correctlabels[idx]):\n",
    "        accuracy[idx] = 1\n",
    "            \n",
    "print(f\"Top-1 accuracy is {sum(accuracy.values())/len(accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c04f8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "values,indices = (img_features.squeeze() @ text_features.T).softmax(dim=1).topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b98ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy is 0.7237580128205128\n"
     ]
    }
   ],
   "source": [
    "accuracy = {}\n",
    "for idx,item in enumerate(indices):\n",
    "    accuracy[idx] = 0\n",
    "    for curr_item in item:\n",
    "        if (curr_item.item() == correctlabels[idx]):\n",
    "            accuracy[idx] = 1\n",
    "            \n",
    "print(f\"Top-5 accuracy is {sum(accuracy.values())/len(accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923c765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p3iv] *",
   "language": "python",
   "name": "conda-env-p3iv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
